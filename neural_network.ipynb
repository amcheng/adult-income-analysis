{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "\n",
    "adult_df = pd.read_csv(\"data/adult_training.csv\",\n",
    "                      delimiter=\",\",\n",
    "                      skipinitialspace=True,\n",
    "                      names = column_names,\n",
    "                      dtype=None)\n",
    "\n",
    "adult_test_df = pd.read_csv(\"data/adult_training.csv\",\n",
    "                      delimiter=\",\",\n",
    "                      skipinitialspace=True,\n",
    "                      names = column_names,\n",
    "                      dtype=None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(y_true, y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    TP = cm[1,1]\n",
    "    TN = cm[0,0]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "\n",
    "    accuracy = ((TP+TN))/(TP+FN+FP+TN)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    recall = (TP)/(TP+FN)\n",
    "    f_measure = (2*recall*precision)/(recall+precision)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    error_rate = 1 - accuracy\n",
    "    false_pos = FP/(FP+TN)\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['accuracy'] =  accuracy\n",
    "    metrics['precision'] = precision\n",
    "    metrics['recall'] = recall\n",
    "    metrics['f_measure'] = f_measure\n",
    "    metrics['sensitivity'] = sensitivity\n",
    "    metrics['specificity'] = specificity\n",
    "    metrics['error_rate'] = error_rate\n",
    "    metrics['false_pos'] = false_pos\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_preprocess(df, balanced=False, impute=False):\n",
    "    \"\"\"adult_preprocess(df, balanced=False, impute=False)\n",
    "            balanced: will sample an even amount of data from each\n",
    "    \n",
    "            impute:\n",
    "                Imputes missing data using random forest,\n",
    "                or removes rows with missing data\n",
    "                \n",
    "        expands categorical data returns X and Y arrays\"\"\"\n",
    "    #drop columns\n",
    "    drop_columns = [\"fnlwgt\"]\n",
    "    df = df.drop(drop_columns , axis=1)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import tree\n",
    "    \n",
    "    \n",
    "    if impute:\n",
    "        impute_df = df.copy()\n",
    "        impute_df.drop(columns = ['income'], inplace=True)\n",
    "        \n",
    "        impute_labels = impute_df.workclass\n",
    "        impute_df.drop(columns = ['workclass'], inplace=True)\n",
    "        \n",
    "        impute_df = pd.get_dummies(impute_df)\n",
    "        \n",
    "        test_data = impute_df[(df.workclass.values == '?')].copy()\n",
    "        \n",
    "        train_data = impute_df[(df.workclass.values != '?')].copy()\n",
    "        train_label = impute_labels[(df.workclass.values != '?')]\n",
    "     \n",
    "        random_forest = RandomForestClassifier(n_estimators=10)\n",
    "        random_forest = random_forest.fit(train_data, train_label)\n",
    "        random_forest_pred = random_forest.predict(test_data)    \n",
    "        df.loc[(df.workclass.values == '?'),'workclass'] = random_forest_pred\n",
    "        \n",
    "        #repeat for occupation\n",
    "        \n",
    "        impute_df = df.copy()\n",
    "        impute_df.drop(columns = ['income'], inplace=True)\n",
    "        \n",
    "        impute_labels = impute_df.occupation\n",
    "        impute_df.drop(columns = ['occupation'], inplace=True)\n",
    "        \n",
    "        impute_df = pd.get_dummies(impute_df)\n",
    "        \n",
    "        test_data = impute_df[(df.occupation.values == '?')].copy()\n",
    "        \n",
    "        train_data = impute_df[(df.occupation.values != '?')].copy()\n",
    "        train_label = impute_labels[(df.occupation.values != '?')]\n",
    "     \n",
    "        random_forest = RandomForestClassifier(n_estimators=10)\n",
    "        random_forest = random_forest.fit(train_data, train_label)\n",
    "        random_forest_pred = random_forest.predict(test_data)    \n",
    "        df.loc[(df.occupation.values == '?'),'occupation'] = random_forest_pred\n",
    "        \n",
    "        # repeat for native-country\n",
    "        \n",
    "        impute_df = df.copy()\n",
    "        impute_df.drop(columns = ['income'], inplace=True)\n",
    "        \n",
    "        impute_labels = impute_df['native-country']\n",
    "        impute_df.drop(columns = ['native-country'], inplace=True)\n",
    "        \n",
    "        impute_df = pd.get_dummies(impute_df)\n",
    "        \n",
    "        test_data = impute_df[(df['native-country'].values == '?')].copy()\n",
    "        \n",
    "        train_data = impute_df[(df['native-country'].values != '?')].copy()\n",
    "        train_label = impute_labels[(df['native-country'].values != '?')]\n",
    "     \n",
    "        random_forest = tree.DecisionTreeClassifier()\n",
    "        random_forest = random_forest.fit(train_data, train_label)\n",
    "        random_forest_pred = random_forest.predict(test_data)    \n",
    "        df.loc[(df['native-country'].values == '?'),'native-country'] = random_forest_pred    \n",
    "    else:\n",
    "        # remove rows with '?'s\n",
    "        df = df[(df != '?').all(1)]\n",
    "    \n",
    "    # convert categorical data into one-hot\n",
    "    df_one_hot = pd.get_dummies(df)\n",
    "    \n",
    "    # sample equal number of plus and minus\n",
    "    if balanced:\n",
    "        # find number of income > $50k\n",
    "        sample_number = len(df_one_hot[df_one_hot['income_>50K'] == 1])\n",
    "        df_over_50k = df_one_hot[df_one_hot['income_>50K'] == 1].sample(n=sample_number, random_state=0)\n",
    "        df_under_50k = df_one_hot[df_one_hot['income_>50K'] == 0].sample(n=sample_number, random_state=0)\n",
    "        frames = [df_over_50k, df_under_50k]\n",
    "        df_clean = pd.concat(frames)\n",
    "    else:\n",
    "        df_clean = df_one_hot\n",
    "    \n",
    "    #randomize data order\n",
    "    df_clean = df_clean.sample(frac=1)\n",
    "    \n",
    "    # split into inputs and targets\n",
    "    X = df_clean.iloc[:,0:-2].values\n",
    "    Y = df_clean.loc[:,'income_>50K'].values\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = adult_preprocess(adult_df, balanced=False, impute=True)\n",
    "scaler = StandardScaler()  # Default behavior is to scale to [0,1]\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_test, Y_test = adult_preprocess(adult_test_df, balanced=False, impute=True)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline(activation = 'relu',depth = 2):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(104, input_dim=104, kernel_initializer='normal', activation=activation))\n",
    "\n",
    "\n",
    "    for i in range(depth):\n",
    "            model.add(Dense (60,kernel_initializer='normal', activation=activation))\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    model.add(Dense(1, kernel_initializer='normal', activation=activation))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b1fbcdb14f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-38d71d967cf1>\u001b[0m in \u001b[0;36mcreate_baseline\u001b[0;34m(activation, depth)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "clf = create_baseline()\n",
    "print X_train.shape\n",
    "clf.fit(X_train,Y_train,batch_size=32,epochs=5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
