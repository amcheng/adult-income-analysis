{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num',\n",
    "                'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "\n",
    "adult_df = pd.read_csv(\"data/adult_training.csv\",\n",
    "                      delimiter=\",\",\n",
    "                      skipinitialspace=True,\n",
    "                      names = column_names,\n",
    "                      dtype=None)\n",
    "\n",
    "adult_test_df = pd.read_csv(\"data/adult_training.csv\",\n",
    "                      delimiter=\",\",\n",
    "                      skipinitialspace=True,\n",
    "                      names = column_names,\n",
    "                      dtype=None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#from joblib import dump, load\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(y_true, y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    TP = cm[1,1]\n",
    "    TN = cm[0,0]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "\n",
    "    accuracy = ((TP+TN))/(TP+FN+FP+TN)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    recall = (TP)/(TP+FN)\n",
    "    f_measure = (2*recall*precision)/(recall+precision)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    error_rate = 1 - accuracy\n",
    "    false_pos = FP/(FP+TN)\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['accuracy'] =  accuracy\n",
    "    metrics['precision'] = precision\n",
    "    metrics['recall'] = recall\n",
    "    metrics['f_measure'] = f_measure\n",
    "    metrics['sensitivity'] = sensitivity\n",
    "    metrics['specificity'] = specificity\n",
    "    metrics['error_rate'] = error_rate\n",
    "    metrics['false_pos'] = false_pos\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_preprocess(df, balanced=False, impute=False):\n",
    "    \"\"\"adult_preprocess(df, balanced=False, impute=False)\n",
    "            balanced: will sample an even amount of data from each\n",
    "    \n",
    "            impute:\n",
    "                Imputes missing data using random forest,\n",
    "                or removes rows with missing data\n",
    "                \n",
    "        expands categorical data returns X and Y arrays\"\"\"\n",
    "    #drop columns\n",
    "    drop_columns = [\"fnlwgt\"]\n",
    "    df = df.drop(drop_columns , axis=1)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn import tree\n",
    "    \n",
    "    \n",
    "    if impute:\n",
    "        impute_df = df.copy()\n",
    "        impute_df.drop(columns = ['income'], inplace=True)\n",
    "        \n",
    "        impute_labels = impute_df.workclass\n",
    "        impute_df.drop(columns = ['workclass'], inplace=True)\n",
    "        \n",
    "        impute_df = pd.get_dummies(impute_df)\n",
    "        \n",
    "        test_data = impute_df[(df.workclass.values == '?')].copy()\n",
    "        \n",
    "        train_data = impute_df[(df.workclass.values != '?')].copy()\n",
    "        train_label = impute_labels[(df.workclass.values != '?')]\n",
    "     \n",
    "        random_forest = RandomForestClassifier(n_estimators=10)\n",
    "        random_forest = random_forest.fit(train_data, train_label)\n",
    "        random_forest_pred = random_forest.predict(test_data)    \n",
    "        df.loc[(df.workclass.values == '?'),'workclass'] = random_forest_pred\n",
    "        \n",
    "        #repeat for occupation\n",
    "        \n",
    "        impute_df = df.copy()\n",
    "        impute_df.drop(columns = ['income'], inplace=True)\n",
    "        \n",
    "        impute_labels = impute_df.occupation\n",
    "        impute_df.drop(columns = ['occupation'], inplace=True)\n",
    "        \n",
    "        impute_df = pd.get_dummies(impute_df)\n",
    "        \n",
    "        test_data = impute_df[(df.occupation.values == '?')].copy()\n",
    "        \n",
    "        train_data = impute_df[(df.occupation.values != '?')].copy()\n",
    "        train_label = impute_labels[(df.occupation.values != '?')]\n",
    "     \n",
    "        random_forest = RandomForestClassifier(n_estimators=10)\n",
    "        random_forest = random_forest.fit(train_data, train_label)\n",
    "        random_forest_pred = random_forest.predict(test_data)    \n",
    "        df.loc[(df.occupation.values == '?'),'occupation'] = random_forest_pred\n",
    "        \n",
    "        # repeat for native-country\n",
    "        \n",
    "        impute_df = df.copy()\n",
    "        impute_df.drop(columns = ['income'], inplace=True)\n",
    "        \n",
    "        impute_labels = impute_df['native-country']\n",
    "        impute_df.drop(columns = ['native-country'], inplace=True)\n",
    "        \n",
    "        impute_df = pd.get_dummies(impute_df)\n",
    "        \n",
    "        test_data = impute_df[(df['native-country'].values == '?')].copy()\n",
    "        \n",
    "        train_data = impute_df[(df['native-country'].values != '?')].copy()\n",
    "        train_label = impute_labels[(df['native-country'].values != '?')]\n",
    "     \n",
    "        random_forest = tree.DecisionTreeClassifier()\n",
    "        random_forest = random_forest.fit(train_data, train_label)\n",
    "        random_forest_pred = random_forest.predict(test_data)    \n",
    "        df.loc[(df['native-country'].values == '?'),'native-country'] = random_forest_pred    \n",
    "    else:\n",
    "        # remove rows with '?'s\n",
    "        df = df[(df != '?').all(1)]\n",
    "    \n",
    "    # convert categorical data into one-hot\n",
    "    df_one_hot = pd.get_dummies(df)\n",
    "    \n",
    "    # sample equal number of plus and minus\n",
    "    if balanced:\n",
    "        # find number of income > $50k\n",
    "        sample_number = len(df_one_hot[df_one_hot['income_>50K'] == 1])\n",
    "        df_over_50k = df_one_hot[df_one_hot['income_>50K'] == 1].sample(n=sample_number, random_state=0)\n",
    "        df_under_50k = df_one_hot[df_one_hot['income_>50K'] == 0].sample(n=sample_number, random_state=0)\n",
    "        frames = [df_over_50k, df_under_50k]\n",
    "        df_clean = pd.concat(frames)\n",
    "    else:\n",
    "        df_clean = df_one_hot\n",
    "    \n",
    "    #randomize data order\n",
    "    df_clean = df_clean.sample(frac=1)\n",
    "    \n",
    "    # split into inputs and targets\n",
    "    X = df_clean.iloc[:,0:-2].values\n",
    "    Y = df_clean.loc[:,'income_>50K'].values\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = adult_preprocess(adult_df, balanced=False, impute=True)\n",
    "scaler = StandardScaler()  # Default behavior is to scale to [0,1]\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_test, Y_test = adult_preprocess(adult_test_df, balanced=False, impute=True)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline(activation = 'relu',depth = 2):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_test.shape[1], input_dim=X_test.shape[1], kernel_initializer='normal', activation=activation))\n",
    "\n",
    "\n",
    "    for i in range(depth):\n",
    "            model.add(Dense (60,kernel_initializer='normal', activation=activation))\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(y_true, y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    TP = cm[1,1]\n",
    "    TN = cm[0,0]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "\n",
    "    accuracy = ((TP+TN))/(TP+FN+FP+TN)\n",
    "    precision = (TP)/(TP+FP)\n",
    "    recall = (TP)/(TP+FN)\n",
    "    f_measure = (2*recall*precision)/(recall+precision)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    error_rate = 1 - accuracy\n",
    "    false_pos = FP/(FP+TN)\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['accuracy'] =  accuracy\n",
    "    metrics['precision'] = precision\n",
    "    metrics['recall'] = recall\n",
    "    metrics['f_measure'] = f_measure\n",
    "    metrics['sensitivity'] = sensitivity\n",
    "    metrics['specificity'] = specificity\n",
    "    metrics['error_rate'] = error_rate\n",
    "    metrics['false_pos'] = false_pos\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error_rate': 0.13344184760910294, 'recall': 0.6522127279683714, 'sensitivity': 0.6522127279683714, 'precision': 0.7596553773024362, 'false_pos': 0.06545307443365696, 'specificity': 0.934546925566343, 'f_measure': 0.7018458793659507, 'accuracy': 0.8665581523908971}\n",
      "{'error_rate': 0.13123061331040198, 'recall': 0.670195128172427, 'sensitivity': 0.670195128172427, 'precision': 0.7569864592336503, 'false_pos': 0.06824433656957929, 'specificity': 0.9317556634304207, 'f_measure': 0.7109517689237639, 'accuracy': 0.868769386689598}\n",
      "{'error_rate': 0.13181413347255921, 'recall': 0.6772095395995409, 'sensitivity': 0.6772095395995409, 'precision': 0.7509546033092914, 'false_pos': 0.0712378640776699, 'specificity': 0.9287621359223301, 'f_measure': 0.7121781115879828, 'accuracy': 0.8681858665274408}\n",
      "{'error_rate': 0.136205890482479, 'recall': 0.583343961229435, 'sensitivity': 0.583343961229435, 'precision': 0.7965865552072449, 'false_pos': 0.04724919093851133, 'specificity': 0.9527508090614887, 'f_measure': 0.6734889199734962, 'accuracy': 0.863794109517521}\n",
      "{'error_rate': 0.13580663984521357, 'recall': 0.5948220890192577, 'sensitivity': 0.5948220890192577, 'precision': 0.7893044508377052, 'false_pos': 0.05036407766990291, 'specificity': 0.9496359223300971, 'f_measure': 0.6784, 'accuracy': 0.8641933601547864}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>f_measure</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 hidden layers</th>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.9345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 hidden layer</th>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.9318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 hidden layers</th>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.9288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 hidden layers</th>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.9528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 hidden layers</th>\n",
       "      <td>0.8642</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.7893</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.9496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  error_rate  f_measure  false_pos  precision  \\\n",
       "0 hidden layers    0.8666      0.1334     0.7018     0.0655     0.7597   \n",
       "1 hidden layer     0.8688      0.1312     0.7110     0.0682     0.7570   \n",
       "2 hidden layers    0.8682      0.1318     0.7122     0.0712     0.7510   \n",
       "3 hidden layers    0.8638      0.1362     0.6735     0.0472     0.7966   \n",
       "4 hidden layers    0.8642      0.1358     0.6784     0.0504     0.7893   \n",
       "\n",
       "                 recall  sensitivity  specificity  \n",
       "0 hidden layers  0.6522       0.6522       0.9345  \n",
       "1 hidden layer   0.6702       0.6702       0.9318  \n",
       "2 hidden layers  0.6772       0.6772       0.9288  \n",
       "3 hidden layers  0.5833       0.5833       0.9528  \n",
       "4 hidden layers  0.5948       0.5948       0.9496  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_metrics = []\n",
    "for i in range(0,5):\n",
    "    clf = create_baseline(depth=i)\n",
    "    clf.fit(X_train,Y_train,batch_size=32,epochs=10, verbose=0)\n",
    "    \n",
    "    y_pred = clf.predict(X_test).round()\n",
    "    \n",
    "    nn_pm = performance_metrics(Y_test, y_pred)\n",
    "    print(nn_pm)\n",
    "    nn_metrics.append(nn_pm)\n",
    "\n",
    "depth_list = [\"0 hidden layers\", \"1 hidden layer\", \"2 hidden layers\", \"3 hidden layers\", \"4 hidden layers\"]\n",
    "nn_df = pd.DataFrame(nn_metrics,index=depth_list).round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>f_measure</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 hidden layers</th>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.9288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 hidden layer</th>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.9318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0 hidden layers</th>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.9345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 hidden layers</th>\n",
       "      <td>0.8642</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.7893</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.9496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 hidden layers</th>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.9528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  error_rate  f_measure  false_pos  precision  \\\n",
       "2 hidden layers    0.8682      0.1318     0.7122     0.0712     0.7510   \n",
       "1 hidden layer     0.8688      0.1312     0.7110     0.0682     0.7570   \n",
       "0 hidden layers    0.8666      0.1334     0.7018     0.0655     0.7597   \n",
       "4 hidden layers    0.8642      0.1358     0.6784     0.0504     0.7893   \n",
       "3 hidden layers    0.8638      0.1362     0.6735     0.0472     0.7966   \n",
       "\n",
       "                 recall  sensitivity  specificity  \n",
       "2 hidden layers  0.6772       0.6772       0.9288  \n",
       "1 hidden layer   0.6702       0.6702       0.9318  \n",
       "0 hidden layers  0.6522       0.6522       0.9345  \n",
       "4 hidden layers  0.5948       0.5948       0.9496  \n",
       "3 hidden layers  0.5833       0.5833       0.9528  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_df.sort_values(by = ['f_measure', 'accuracy'], ascending = False, inplace = True)\n",
    "display(nn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8681858665274408,\n",
       " 'error_rate': 0.13181413347255921,\n",
       " 'f_measure': 0.7121781115879828,\n",
       " 'false_pos': 0.0712378640776699,\n",
       " 'precision': 0.7509546033092914,\n",
       " 'recall': 0.6772095395995409,\n",
       " 'sensitivity': 0.6772095395995409,\n",
       " 'specificity': 0.9287621359223301}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_metrics[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'performance_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-42ed16f71793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnn_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Neural Network\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'performance_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "nn_performance = performance_metrics(Y_test, y_pred)\n",
    "\n",
    "nn_df = pd.DataFrame([nn_metrics[2]],index=[\"Neural Network\"]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e82e1a1111a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>f_measure</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.6664</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>0.9476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy  error_rate  f_measure  false_pos  precision  recall  \\\n",
       "Neural Network    0.8596      0.1404     0.6664     0.0524      0.779  0.5822   \n",
       "\n",
       "                sensitivity  specificity  \n",
       "Neural Network       0.5822       0.9476  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = \"nn.csv\"\n",
    "nn_df.to_csv(file_name, encoding='utf-8', index=True)\n",
    "\n",
    "csv_nn_df = pd.read_csv(file_name, encoding='utf-8', index_col=0)\n",
    "display(csv_nn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
