{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "adult = pd.read_csv(\"data/adult_training.csv\",\n",
    "                      delimiter=\",\",\n",
    "                      skipinitialspace=True,\n",
    "                        #nrows=10000,\n",
    "                      dtype=None)\n",
    "\n",
    "adult_test = pd.read_csv(\"data/adult_training.csv\",\n",
    "                      delimiter=\",\",\n",
    "                      skipinitialspace=True,\n",
    "                        #nrows=10000,\n",
    "                      dtype=None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sys\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_preprocess_balanced(adult):\n",
    "    \"\"\"Takes in an adult income pandas dataframe, removes '?', \n",
    "    expands categorical data returns X and Y arrays\"\"\"\n",
    "    \n",
    "    # remove rows with '?'s\n",
    "    adult = adult[(adult != '?').all(1)]\n",
    "    \n",
    "    # convert categorical data into one-hot\n",
    "    adult_one_hot = pd.get_dummies(adult)\n",
    "    \n",
    "    adult_over_50k = adult_one_hot[adult_one_hot['income_>50K'] == 1].sample(n=7500, random_state=0)\n",
    "    adult_under_50k = adult_one_hot[adult_one_hot['income_>50K'] == 0].sample(n=7500, random_state=0)\n",
    "    \n",
    "    frames = [adult_over_50k, adult_under_50k]\n",
    "    \n",
    "    adult_clean = pd.concat(frames)\n",
    "    adult_clean = adult_clean.sample(frac=1)\n",
    "    \n",
    "    # split into inputs and targets\n",
    "    X = adult_clean.iloc[:,0:-2].values\n",
    "    Y = adult_clean.loc[:,'income_>50K'].values\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_preprocess_unbalanced(adult):\n",
    "    \"\"\"Takes in an adult income pandas dataframe, removes '?', \n",
    "    expands categorical data returns X and Y arrays\"\"\"\n",
    "    \n",
    "    # remove rows with '?'s\n",
    "    adult = adult[(adult != '?').all(1)]\n",
    "    \n",
    "    # convert categorical data into one-hot\n",
    "    adult_one_hot = pd.get_dummies(adult)\n",
    "\n",
    "    # split into inputs and targets\n",
    "    X = adult_one_hot.iloc[:,0:-2].values\n",
    "    Y = adult_one_hot.loc[:,'income_>50K'].values\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    36 196529     14      0      0     40      0      1      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      1      0      0      0      0\n",
      "      0      1      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      1      0      0      0      0\n",
      "      0      0      0      0      0      1      0      0      0      0\n",
      "      1      1      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      1      0      0]\n"
     ]
    }
   ],
   "source": [
    "X, Y = adult_preprocess_balanced(adult)\n",
    "print(X[1])\n",
    "# scaler = StandardScaler()  # Default behavior is to scale to [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_test, Y_test = adult_preprocess_balanced(adult_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  kernel types = ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ \n",
    "\n",
    "# for i in range(100):\n",
    "    \n",
    "#     classifiers[i] = SVC(gamma='auto', kernel = \"linear\")\n",
    "    \n",
    "#     X_train_sample, Y_train_sample = resample(X_train,Y_train, n_samples=500, replace=False)\n",
    "#     classifiers[i].fit(X_train_sample,Y_train_sample)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# bag = SVC(gamma='auto', kernel = \"linear\")\n",
    "\n",
    "# # bag =  BaggingClassifier(SVC(gamma='auto', kernel = 'sigmoid'),\n",
    "# #                              max_samples=0.2, n_estimators = 1000,n_jobs = 5)\n",
    "\n",
    "# bag.fit(X_train,Y_train)\n",
    "\n",
    "# # dump(bag,'svmBag_sigmoid.joblib')\n",
    "\n",
    "# end = time.time()\n",
    "# print(end - start)\n",
    "\n",
    "# bag =  BaggingClassifier(SVC(gamma='auto', kernel = 'poly'),\n",
    "#                              max_samples=0.1, n_estimators = 50,n_jobs = 5)\n",
    "\n",
    "# bag.fit(X_train,Y_train)\n",
    "\n",
    "# dump(bag,'svmBag_linear.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CValue = 2.0 ** np.arange(-5,16,2)\n",
    "# GammaValue = 2.0 ** np.arange(-15,4,2)\n",
    "# for c in CValue:\n",
    "#     for gamma in GammaValue:\n",
    "#         clf = SVC(kernel='rbf', C=c, gamma = gamma)\n",
    "#         scores = cross_val_score(clf, X_train, Y_train, cv=5)\n",
    "#         print(\"Accuracy with a gamma %0.5f and c %0.2f: %0.2f (+/- %0.2f)\" % (gamma, c, scores.mean(), scores.std() * 2))\n",
    "#         sys.stdout.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Done  ', 'rbf14.6808309555')\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf','linear','sigmoid','poly']\n",
    "c = 2 ** 13\n",
    "gamma =  2 **(-11)\n",
    "for kernel in kernels:\n",
    "        start = time.time()\n",
    "        clf = SVC(kernel=kernel, C=c, gamma = gamma)\n",
    "        clf.fit(X_train,Y_train)\n",
    "        dump(clf,'svm_' + kernel + '.joblib')\n",
    "        print('Done  ' , kernel +  str(time.time()- start) )\n",
    "        sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  5 bag\n",
      "Done  10 bag\n",
      "Done  15 bag\n",
      "Done  20 bag\n",
      "Done  25 bag\n",
      "Done  30 bag\n",
      "Done  35 bag\n",
      "Done  40 bag\n",
      "Done  45 bag\n",
      "Done  50 bag\n",
      "Done  55 bag\n",
      "Done  60 bag\n",
      "Done  65 bag\n",
      "Done  70 bag\n",
      "Done  75 bag\n",
      "Done  80 bag\n",
      "Done  85 bag\n",
      "Done  90 bag\n",
      "Done  95 bag\n",
      "Done  100 bag\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "c = 2 ** 13\n",
    "gamma =  2 **(-11)\n",
    "# bag = SVC(gamma='auto', kernel = \"linear\")\n",
    "\n",
    "for n_estimator in range (5,101, 5):\n",
    "    bag =  BaggingClassifier(SVC(gamma=gamma, kernel = 'rbf', C=c),\n",
    "                                 max_samples=0.2, n_estimators = n_estimator, n_jobs = 5)\n",
    "\n",
    "    bag.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "    dump(bag,'svmBag_' + str(n_estimator) +'.joblib')\n",
    "    print('Done  ' + str(n_estimator) + ' bag' )\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(Y_true, Y_pred):\n",
    "    \"\"\"Prints metrics comparing true and predicted classifications\"\"\"\n",
    "    \n",
    "    cm_test = confusion_matrix(y_true=Y_true, y_pred=Y_pred)\n",
    "\n",
    "    total = cm_test.sum()\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(len(cm_test)):\n",
    "        correct += cm_test[i,i]\n",
    "    \n",
    "    acc = correct/total\n",
    "    \n",
    "    print(\"Confusion Matrix:\\n\")\n",
    "    print(\"      predicted class:\")\n",
    "    print(\"          0\\t1\")\n",
    "    print(\"        _____________\")\n",
    "    print(\"true  0| {}\\t{}\".format(cm_test[0,0], cm_test[0,1]))\n",
    "    print(\"class 1| {}\\t{}\".format(cm_test[1,0], cm_test[1,1]))\n",
    "    print(\"\")\n",
    "    print(\"Correct: \\t{}\".format(correct))\n",
    "    print(\"Misclassified: \\t{}\".format(total-correct))\n",
    "    print(\"Accuracy: \\t{:.2f}%\".format(acc*100))\n",
    "    print(\"Error rate: \\t{:.2f}%\".format((1-acc)*100))\n",
    "    print(\"Sensitivity: \\t{:.2f}% (true positive)\".format(cm_test[1,1]*100 / cm_test[1].sum()))\n",
    "    print(\"Specificity: \\t{:.2f}% (true negative)\".format(cm_test[0,0]*100 / cm_test[0].sum()))\n",
    "    print(\"Precision: \\t{:.2f}% (positive predict value)\".format(100*cm_test[1,1] / cm_test[:,1].sum()))\n",
    "    print(\"False Pos: \\t{:.2f}%\".format(100*cm_test[0,1] / cm_test[0].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load('svm_rbf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "      predicted class:\n",
      "          0\t1\n",
      "        _____________\n",
      "true  0| 1196\t348\n",
      "class 1| 194\t1262\n",
      "\n",
      "Correct: \t2458\n",
      "Misclassified: \t542\n",
      "Accuracy: \t81.93%\n",
      "Error rate: \t18.07%\n",
      "Sensitivity: \t86.68% (true positive)\n",
      "Specificity: \t77.46% (true negative)\n",
      "Precision: \t78.39% (positive predict value)\n",
      "False Pos: \t22.54%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "print_metrics(Y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
